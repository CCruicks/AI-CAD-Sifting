{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "running-relay",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "import torch\n",
    "import pre_process as proc\n",
    "import models, parameters, histories, trainer\n",
    "import glovar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "domestic-concentrate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting history with name model_name; override=False...\n",
      "Exists: False\n",
      "Creating...\n",
      "Config as follows:\n",
      "\t_lambda \t\t0.0\n",
      "\tbatch_size \t\t32\n",
      "\tgrad_clip_norm \t\t0.0\n",
      "\thidden_size \t\t300\n",
      "\tlearning_rate \t\t0.001\n",
      "\tp_keep_fc \t\t0.9\n",
      "\tp_keep_input \t\t0.9\n",
      "\tp_keep_rnn \t\t0.9\n",
      "\tprojection_size \t200\n",
      "\ttune_embeddings \tFalse\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set global directories\n",
    "glovar.set_dirs()\n",
    "\n",
    "# Parse configuration settings from command line\n",
    "sys.argv[1:] = [\"model_name\"]\n",
    "params, arg_config = parameters.parse_arguments()\n",
    "\n",
    "\n",
    "# Get or create History\n",
    "history = histories.get(\n",
    "    glovar.PKL_DIR, params.name, params.override, arg_config)\n",
    "\n",
    "\n",
    "# Report config to be used\n",
    "config = history.config\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "searching-music",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from stored dataset\n",
      "Done. Processed dataset read in 0m, 44s.\n",
      "Reading from stored dataset\n",
      "Done. Processed dataset read in 0m, 12s.\n",
      "No processed dataset found.\n",
      "Processing VAL dataset (2400 files)...\n",
      "Done. 2400 files processed in 7m, 8s.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-93199917ddbf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mquit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0membedding_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mproc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetEmbeddings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\Uni\\postgrad\\Code\\AI_engineering_management\\treelstm\\pre_process.py\u001b[0m in \u001b[0;36mgetEmbeddings\u001b[1;34m(labels)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgetEmbeddings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 189\u001b[1;33m     \u001b[0membedding_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    190\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m         \u001b[0membedding_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0membedding_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgetWordVector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\torchenv\\lib\\site-packages\\torch\\cuda\\__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    170\u001b[0m         \u001b[1;31m# This function throws if there's a driver initialization error, no GPUs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[1;31m# are found or any other error occurs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 172\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    173\u001b[0m         \u001b[1;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m         \u001b[1;31m# we need to just return without initializing in that case.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
     ]
    }
   ],
   "source": [
    "# Get training datasets, node labels and vector representations\n",
    "train_set, labels = proc.procDataset(\"TRAIN\")\n",
    "test_set, _ = proc.procDataset(\"TEST\", labels)\n",
    "val_set, _ = proc.procDataset(\"VAL\", labels)\n",
    "if not test_set or not val_set:\n",
    "    quit()\n",
    "\n",
    "embedding_matrix = proc.getEmbeddings(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustained-universe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training datasets into batches\n",
    "batch_size = config.batch_size\n",
    "train_batches = trainer.batchDataset(batch_size, train_set)\n",
    "test_batches = trainer.batchDataset(batch_size, test_set)\n",
    "val_batches = trainer.batchDataset(5, val_set)\n",
    "print(\"{} batches of size {} in training dataset.\".format(len(train_batches), batch_size))\n",
    "print(\"{} batches of size {} in tuning dataset\".format(len(test_batches), batch_size))\n",
    "print(\"{} batches of size 5 in validation dataset\".format(len(val_batches)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "linear-harbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "print('Loading model...')\n",
    "model = models.ClassificationModel(params.name, config, embedding_matrix)\n",
    "\n",
    "print('Loading trainer...')\n",
    "tr = trainer.Trainer(model, history, train_batches, test_batches, glovar.CKPT_DIR)\n",
    "\n",
    "print('Training...')\n",
    "tr.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infinite-declaration",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_data = []\n",
    "for i in range(len(history.epoch_losses)):\n",
    "    x_data.append(i + 1)\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "plt.xticks(np.arange(0, len(history.epoch_losses) + 1, step = 5))\n",
    "ax.grid(linewidth=1)\n",
    "ax.set_title('Training loss')\n",
    "ax.set_xlabel('epoch')\n",
    "ax.set_ylabel('loss')\n",
    "fig.tight_layout()\n",
    "ax.plot(x_data, history.epoch_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frequent-luxembourg",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = []\n",
    "for i in range(len(history.epoch_accs)):\n",
    "    x_data.append(i + 1)\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "plt.xticks(np.arange(0, len(history.epoch_accs) + 1, step=5))\n",
    "plt.yticks(np.arange(0, 1, step=0.1))\n",
    "ax.grid(linewidth=1)\n",
    "ax.set_title('Model Accuracy')\n",
    "ax.set_xlabel('epoch')\n",
    "ax.set_ylabel('accuracy')\n",
    "fig.tight_layout()\n",
    "ax.plot(x_data, history.epoch_accs, 'k')\n",
    "ax.plot(x_data, history.tuning_accs, 'r')\n",
    "ax.legend(['train accuracy', 'test accuracy'])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torchenv] *",
   "language": "python",
   "name": "conda-env-torchenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
